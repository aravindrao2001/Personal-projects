# -*- coding: utf-8 -*-
"""assignment5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16crEMEBp-4QPK9JZ42PCA8IBfBFh9N4N

#A
Pick any publicly-traded company that trades on the Nasdaq or the NYSE.


a. What company did you select, and what is its ticker symbol?


Apple Inc., which trades on the Nasdaq under the ticker symbol "AAPL".

#B
Loaded the data
"""

#c
import pandas as pd

apple=pd.read_csv("AAPL.csv",index_col="Date",parse_dates=True)

apple.head(10)

#c

apple.info()

#D

# check the data type of the index column
print(apple.index.dtype)

"""#D
The DataFrame provided is indexed by time values, as evidenced by the "Date" column and confirmed by checking the data type of the index column.

#E (A)
Now, view the max and min value of your index attribute.
"""

#E (a)

apple.index.max()

#E (a)

apple.index.min()

"""#E(B)
Now, view the argmax and argmin values of your index attribute.

"""

#E(B)
apple.index.argmax()

#E(B)
apple.index.argmin()

"""What do the results of max, min, argmax, and argmin represent?

max and min: These are the maximum and minimum values in the index, respectively. In a time-based index, these values represent the latest and earliest dates/times in the DataFrame.



argmax and argmin: These are the indices (i.e., row numbers) that correspond to the maximum and minimum values in the index, respectively. In a time-based index, these values represent the row numbers that correspond to the latest and earliest dates/times in the DataFrame.



So, in the context of the DataFrame provided, if the max and min values of the index are '2023-04-21' and '2022-04-25', respectively, then the DataFrame covers a period of time from April 25, 2022 to April 21, 2023. And if the argmax and argmin values of the index are 249 and 0, respectively, then the latest date/time is in row 249 of the DataFrame, and the earliest date/time is in row 0 of the DataFrame.
"""

#F(a)

apple.plot()

"""
#F(a)
the plot shows multiple lines, it may be challenging to interpret because it can be difficult to distinguish between the different lines and to determine which line corresponds to which variable. Additionally, the plot may be difficult to read if the x-axis labels are not formatted in a clear and consistent manner, or if there are too many data points or too much information displayed at once.

To make the plot easier to understand, it can be helpful to add labels to the axes and to the individual lines, to use different colors or line styles for different lines, and to adjust the scale and formatting of the axes to better display the data. Additionally, it may be helpful to plot subsets of the data at a time or to aggregate the data in a meaningful way before plotting it.


As seen ,its trying to plot for all the axes and its really important to choose the ones that makes sense and helpful to the model as said above."""

#F(B)
apple['Close'].plot()

"""#F(B)

Plotting the 'Close' variable only makes the graph more easily interpretable because it simplifies the visual representation to only show the closing prices for the stock. This allows for a clearer understanding of the overall trend of the stock price over time, without the potential confusion of having multiple lines for different variables.
"""

#C(I)

apple['2022-04-01':'2022-04-30']['Close'].plot()

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
apple['2022-04-01':'2022-04-30']['Close'].plot(color='red', linestyle='--')
plt.title('Apple Stock Prices in April 2022')
plt.xlabel('Date')
plt.ylabel('Closing Price ($)')
plt.show()

#G(A)

# Compute the 10-period moving average
ma = apple['Close'].rolling(window=10).mean()

# Create a figure and axis objects
fig, ax = plt.subplots(figsize=(10, 6))

# Plot the actual closing prices and the moving average
ax.plot(apple['Close'], label='Actual Closing Prices')
ax.plot(ma, label='10-Period Moving Average')

# Set the axis labels and legend
ax.set_xlabel('Date')
ax.set_ylabel('Closing Price ($)')
ax.legend()

# Show the plot
plt.show()

#G(B)

# Compute the 50-period moving average
ma = apple['Close'].rolling(window=50).mean()

# Create a figure and axis objects
fig, ax = plt.subplots(figsize=(10, 6))

# Plot the actual closing prices and the moving average
ax.plot(apple['Close'], label='Actual Closing Prices')
ax.plot(ma, label='50-Period Moving Average')

# Set the axis labels and legend
ax.set_xlabel('Date')
ax.set_ylabel('Closing Price ($)')
ax.legend()

# Show the plot
plt.show()

"""#G(C)

The 10-period moving average plot responds more quickly to recent changes in the closing prices, while the 50-period moving average plot responds more slowly and is smoother.

Shorter moving average windows (such as the 10-period moving average) have the advantage of being more responsive to recent changes in prices, allowing traders to identify trends earlier. However, they are also more volatile and susceptible to false signals, which can lead to losses. Longer moving average windows (such as the 50-period moving average) are less volatile and smoother, making it easier to identify long-term trends. However, they are less responsive to recent changes in prices, which can result in missed opportunities to enter or exit trades. Ultimately, the choice of moving average window length will depend on the trading strategy and time horizon of the trader.

Resampling
"""

#H (I)
apple_quarterly = apple['Close'].resample('Q').mean()
print(apple_quarterly)

#H (I)
fig, ax = plt.subplots(figsize=(10, 5))
apple_quarterly.plot(ax=ax)

# set the x-axis label
ax.set_xlabel('Date')

# set the y-axis label
ax.set_ylabel('Closing Price (USD)')

# set the plot title
ax.set_title('Apple Quarterly Closing Prices')

# show the plot
plt.show()

"""#H(II)

One example where resampling a time series is important is in weather forecasting. Daily weather data might not be sufficient for some analyses or applications. For example, if you wanted to assess the trend in average temperature over a year or a decade, it would be more appropriate to use monthly or yearly average temperatures instead of daily temperatures. Resampling the time series to a coarser frequency, such as monthly or yearly, can help smooth out short-term fluctuations and reveal longer-term patterns in the data.

#Part II: Marketing Mix Modeling with an Interaction Term
"""

adv=pd.read_csv("schwab_ads.csv")

adv.head(12)

# create a new variable 'Total_Spending' that shows the total spending
adv['Total_Spending'] = adv['Web'] + adv['Bus_Stop'] + adv['Newspaper']

adv.head(10)

adv['Total_spend'].corr(adv['Sales'])

"""The high correlation value of 0.92 suggests a strong positive linear relationship between total marketing spending and sales. However, correlation does not imply causation. There may be other factors that influence sales, such as market demand, competition, product quality, pricing, etc. Also, the relationship may not be linear or may have a time lag. Therefore, we cannot conclude from this correlation alone that more ad spending leads to more sales. Further analysis, such as regression modeling, controlled experiments, and domain expertise, may be needed to establish causal relationships and make actionable recommendations."""

#C

adv[['Web','Bus_Stop','Newspaper']].corr()

""" **Are any of these correlations so high that we might not be able to use
them together in a linear model?**

No, none of the correlations are so high that we might not be able to use them together in a linear model. A correlation of 1 would indicate a perfect linear relationship, but the highest correlation value here is only 0.354104, which suggests a relatively weak linear relationship between bus stop ad spending and newspaper ad spending. However, all three variables can still be used together in a linear model, as long as we are aware of their respective correlations and interpret the results accordingly.
"""

import statsmodels.api as sm

X = sm.add_constant(adv[['Web', 'Bus_Stop', 'Newspaper']])
y = adv['Sales']

model1 = sm.OLS(y, X).fit()
print(model1.summary())

"""#D(I)

What is the p-value of the F-Statistic for this model? What does this
suggest about the model?

The F-statistic for the model is 605.4 and the corresponding p-value is 8.13e-99. This suggests that the model is statistically significant and that at least one of the predictors (web spending, bus stop ad spending, newspaper spending) is significantly related to the outcome variable (sales).

#D(II)

 **What are the p-values for each of the individual predictors used in this
model? What does this suggest about these predictors?**


The p-values for each of the individual predictors used in this model are:

Web: 0.000
Bus_Stop: 0.000
Newspaper: 0.954
These p-values suggest that Web and Bus_Stop have a statistically significant relationship with Sales, while Newspaper does not. Specifically, the low p-values for Web and Bus_Stop indicate that there is strong evidence to reject the null hypothesis that the coefficients for these variables are equal to zero. In contrast, the high p-value for Newspaper suggests that we do not have enough evidence to reject the null hypothesis for this variable, and that it is not a significant predictor of Sales in this model.
"""

#E
import statsmodels.api as sm

adv['Interaction'] = adv['Web'] * adv['Bus_Stop']

X = adv[['Web', 'Bus_Stop', 'Interaction']]
y = adv['Sales']

X = sm.add_constant(X)

model2 = sm.OLS(y, X).fit()

print(model2.summary())

"""#E(I)
**What do you notice about the p-values for each of these predictors?**

The p-values for all three predictors are statistically significant at the 0.05 level, indicating that they are all likely to have a significant impact on the outcome variable (Sales) in this model. The p-value for the interaction term is also statistically significant, suggesting that there is a significant interaction effect between web ad spending and bus stop ad spending on Sales.

#E(II)
How does the r-squared of this model compare to the r-squared of a
model built to predict sales, but with only bus bus stop spending and web
ad spending, but without the interaction term? What does this difference
suggest about the inclusion of the interaction? (you will need to
generate another model to answer this, but it won’t take long)
"""

import statsmodels.api as sm

X = adv[['Web', 'Bus_Stop']]
y = adv['Sales']

X = sm.add_constant(X)

model3 = sm.OLS(y, X).fit()
predictions = model3.predict(X)

print(model3.summary())

"""#E(II)

The R-squared of this model is 0.903.

Comparing this to the R-squared of the model with the interaction term (0.914), we can see that the model with the interaction term has a higher R-squared value, indicating that it explains more of the variance in the data.

This suggests that the interaction term is a significant predictor and adds value to the model. Including the interaction term allows us to capture the combined effect of bus stop and web ad spending on sales, which we would miss if we only included these variables separately.
"""

import numpy as np

# input values
web = 220
bus_stop = 30


# coefficients from model
coef = np.array([4.6309, 0.0544, 0.1072])

# calculate predicted sales
sales_pred = np.dot(coef, np.array([1, web, bus_stop]))

print("Predicted Sales: ", sales_pred)

"""#E(IV)

The interaction effect between bus stop and web ad spending suggests that the combination of these two advertising methods has a greater impact on sales than the sum of their individual effects. In other words, the effect of web ad spending on sales depends on the level of bus stop ad spending and vice versa. The predicted sales for a marketer using 220 units of web ad spending and 30 units of bus stop ad spending is 19.8149.
"""

#F
import statsmodels.api as sm

X = adv[['Web', 'Bus_Stop', 'Total_spend']]
X['Web_Total'] = X['Web'] * X['Total_spend']
X['Bus_Stop_Total'] = X['Bus_Stop'] * X['Total_spend']
y = adv['Sales']

X = sm.add_constant(X)
model = sm.OLS(y, X).fit()

print(model.summary())

"""In this model, there is an interaction term between the variables Web and Total_spend, as well as an interaction term between Bus_Stop and Total_spend. The effect of the interaction term between Web and Total_spend is negative, meaning that the effect of Total_spend on Sales decreases as Web spending increases. The effect of the interaction term between Bus_Stop and Total_spend is positive, meaning that the effect of Total_spend on Sales increases as Bus_Stop spending increases. This interaction makes sense as it suggests that the impact of Total_spend on Sales is not the same across different levels of spending on Web and Bus_Stop advertising.

**Part III: Wildcard: A Real-World Consulting Opportunity**

One possible recommendation is to use an online platform for grading assignments, such as Blackboard or Turnitin. This would allow the lecturer to easily delegate grading to TAs or even peer-reviewers, while maintaining consistency in grading standards. Another option is to implement self-grading or peer grading assignments, where students are given rubrics to grade each other's work, with the lecturer serving as a final arbiter for any discrepancies. This can also provide students with valuable feedback and improve their understanding of course material. Additionally, implementing automated grading tools, such as Grammarly or Turnitin's Feedback Studio, can help reduce the time spent grading assignments, although it may not be appropriate for all types of assignments. Finally, the lecturer can consider reducing the number of assignments or adjusting the workload to make grading more manageable.


Another additional point would be -
using a combination of TA grading and peer grading could also be considered, where students grade each other's assignments under the supervision of the TA. This can be a good way to reduce the workload on the lecturer while also encouraging student engagement and feedback.
"""

!pip install nbconvert

!jupyter nbconvert --to html assignment5.ipynb